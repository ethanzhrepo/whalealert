# ğŸš€ Analyze Agent å¿«é€Ÿå¼€å§‹æŒ‡å—

## ä¸€é”®å®‰è£…å’Œè¿è¡Œ

### 1. å®‰è£…ç¨‹åºä¾èµ–

```bash
./setup.sh
```

è¿™ä¸ªè„šæœ¬ä¼šè‡ªåŠ¨ï¼š
- âœ… æ£€æŸ¥Pythonç‰ˆæœ¬ï¼ˆéœ€è¦3.8+ï¼‰
- âœ… å®‰è£…æ‰€æœ‰Pythonä¾èµ–åŒ…
- âœ… åˆ›å»ºé…ç½®æ–‡ä»¶
- âœ… è¿è¡ŒåŸºç¡€æµ‹è¯•

**æ³¨æ„**: æœ¬ç¨‹åºæ˜¯ç³»ç»Ÿçš„ä¸€ä¸ªç»„ä»¶ï¼Œéœ€è¦å¤–éƒ¨NATSæœåŠ¡å™¨å’ŒLLMæœåŠ¡æ”¯æŒã€‚

### 2. å¯åŠ¨å¤–éƒ¨æœåŠ¡

**åœ¨å¯åŠ¨ç¨‹åºå‰ï¼Œè¯·ç¡®ä¿ä»¥ä¸‹æœåŠ¡å·²è¿è¡Œï¼š**

**NATSæœåŠ¡å™¨ï¼š**
```bash
# ä½¿ç”¨Dockerå¯åŠ¨NATS
docker run -d --name nats -p 4222:4222 nats:latest
```

**LLMæœåŠ¡ï¼ˆé€‰æ‹©å…¶ä¸€ï¼‰ï¼š**
```bash
# é€‰é¡¹1: Ollamaï¼ˆæœ¬åœ°LLMï¼‰
ollama serve

# é€‰é¡¹2: é…ç½®OpenAI APIå¯†é’¥ï¼ˆç¼–è¾‘config.ymlï¼‰
# é€‰é¡¹3: é…ç½®Anthropic APIå¯†é’¥ï¼ˆç¼–è¾‘config.ymlï¼‰
```

### 3. å¯åŠ¨ç¨‹åº

```bash
./run.sh
```

è¿™ä¸ªè„šæœ¬ä¼šè‡ªåŠ¨ï¼š
- âœ… æ£€æŸ¥é…ç½®æ–‡ä»¶
- âœ… æ£€æŸ¥å¤–éƒ¨æœåŠ¡è¿æ¥çŠ¶æ€
- âœ… è¿è¡Œé¢„æ£€æµ‹è¯•
- âœ… å¯åŠ¨åˆ†æç³»ç»Ÿ

## ğŸ› ï¸ é«˜çº§ç”¨æ³•

### å®‰è£…é€‰é¡¹

```bash
# åŸºç¡€å®‰è£…
./setup.sh

# å¦‚æœå®‰è£…è¿‡ç¨‹ä¸­æ–­ï¼Œå¯ä»¥é‡æ–°è¿è¡Œ
./setup.sh
```

### è¿è¡Œé€‰é¡¹

```bash
# æ­£å¸¸å¯åŠ¨ï¼ˆä¼šæ£€æŸ¥å¤–éƒ¨æœåŠ¡è¿æ¥ï¼‰
./run.sh

# åªæ£€æŸ¥æœåŠ¡çŠ¶æ€ï¼Œä¸å¯åŠ¨
./run.sh --check-only

# è·³è¿‡å¤–éƒ¨æœåŠ¡è¿æ¥æ£€æŸ¥ï¼Œç›´æ¥å¯åŠ¨
./run.sh --skip-service-check

# æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
./run.sh --help
```

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

### å¿…éœ€
- **Python 3.8+** (æ”¯æŒpythonæˆ–python3å‘½ä»¤)
- **pip** (PythonåŒ…ç®¡ç†å™¨)

### å¤–éƒ¨æœåŠ¡ä¾èµ–ï¼ˆéœ€è¦æ‰‹åŠ¨å¯åŠ¨ï¼‰
- **NATSæœåŠ¡å™¨** (ç«¯å£4222) - æ¶ˆæ¯é˜Ÿåˆ—
- **LLMæœåŠ¡** - ä»¥ä¸‹ä¹‹ä¸€:
  - Ollama (ç«¯å£11434) - æœ¬åœ°LLM
  - OpenAI API - äº‘ç«¯LLM
  - Anthropic API - äº‘ç«¯LLM

### å¯é€‰
- **Docker** (ç”¨äºå¯åŠ¨NATSæœåŠ¡å™¨)

## âš™ï¸ é…ç½®è¯´æ˜

### LLMæä¾›å•†é…ç½®

ç¼–è¾‘ `config.yml` æ–‡ä»¶ï¼š

**ä½¿ç”¨Ollamaï¼ˆé»˜è®¤ï¼‰ï¼š**
```yaml
llm:
  provider: 'ollama'
  ollama:
    base_url: 'http://localhost:11434'
    model: 'llama3.1:8b'
```

**ä½¿ç”¨OpenAIï¼š**
```yaml
llm:
  provider: 'openai'
  openai:
    api_key: 'your-openai-api-key'
    model: 'gpt-4o-mini'
```

**ä½¿ç”¨Anthropicï¼š**
```yaml
llm:
  provider: 'anthropic'
  anthropic:
    api_key: 'your-anthropic-api-key'
    model: 'claude-3-haiku-20240307'
```

### NATSé…ç½®

```yaml
nats:
  enabled: true
  servers: 
    - 'nats://localhost:4222'
  subject: 
    - 'messages.stream'
```

## ğŸ”§ å¤–éƒ¨æœåŠ¡è®¾ç½®

### NATSæœåŠ¡å™¨

**é€‰é¡¹1: ä½¿ç”¨Dockerï¼ˆæ¨èï¼‰**
```bash
docker run -d --name nats -p 4222:4222 nats:latest
```

**é€‰é¡¹2: æ‰‹åŠ¨å®‰è£…**
- è®¿é—® https://nats.io/download/
- ä¸‹è½½å¹¶å®‰è£…NATSæœåŠ¡å™¨
- å¯åŠ¨: `nats-server`

### LLMæœåŠ¡

**é€‰é¡¹1: Ollamaï¼ˆæœ¬åœ°LLMï¼‰**
```bash
# å®‰è£…Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# å¯åŠ¨æœåŠ¡
ollama serve

# ä¸‹è½½æ¨¡å‹
ollama pull llama3.1:8b
```

**é€‰é¡¹2: OpenAI API**
- è·å–APIå¯†é’¥: https://platform.openai.com/
- åœ¨config.ymlä¸­é…ç½®api_key

**é€‰é¡¹3: Anthropic API**
- è·å–APIå¯†é’¥: https://console.anthropic.com/
- åœ¨config.ymlä¸­é…ç½®api_key

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **Pythonç‰ˆæœ¬æˆ–å‘½ä»¤é—®é¢˜**
   ```bash
   # æ£€æŸ¥Pythonç‰ˆæœ¬
   python --version
   python3 --version
   
   # ç¡®ä¿ç‰ˆæœ¬ >= 3.8
   ```

2. **NATSè¿æ¥å¤±è´¥**
   ```bash
   # æ£€æŸ¥NATSæœåŠ¡å™¨
   nc -z localhost 4222
   
   # å¯åŠ¨NATSæœåŠ¡å™¨
   docker run -d --name nats -p 4222:4222 nats:latest
   ```

3. **LLMæœåŠ¡ä¸å¯ç”¨**
   ```bash
   # æ£€æŸ¥OllamaæœåŠ¡
   curl http://localhost:11434/api/version
   
   # å¯åŠ¨OllamaæœåŠ¡
   ollama serve
   
   # æˆ–è€…é…ç½®ä½¿ç”¨OpenAI/Anthropic API
   ```

4. **ä¾èµ–å®‰è£…å¤±è´¥**
   ```bash
   # å‡çº§pip
   pip install --upgrade pip
   
   # æ‰‹åŠ¨å®‰è£…ä¾èµ–
   pip install -r requirements.txt
   ```

5. **æƒé™é—®é¢˜**
   ```bash
   # ç»™è„šæœ¬æ·»åŠ æ‰§è¡Œæƒé™
   chmod +x setup.sh run.sh
   ```

### æ—¥å¿—æŸ¥çœ‹

```bash
# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
./run.sh

# åªæ£€æŸ¥æœåŠ¡çŠ¶æ€
./run.sh --check-only

# è·³è¿‡æœåŠ¡æ£€æŸ¥ç›´æ¥å¯åŠ¨
./run.sh --skip-service-check

# è¿è¡Œæµ‹è¯•
python simple_test.py
python test_agent.py
```

## ğŸ“Š éªŒè¯å®‰è£…

### 1. è¿è¡ŒåŸºç¡€æµ‹è¯•
```bash
python simple_test.py
```

### 2. è¿è¡Œå®Œæ•´æµ‹è¯•ï¼ˆéœ€è¦LLMæœåŠ¡ï¼‰
```bash
python test_agent.py
```

### 3. æ£€æŸ¥æœåŠ¡çŠ¶æ€
```bash
./run.sh --check-only
```

## ğŸ¯ ä½¿ç”¨æµç¨‹

1. **å®‰è£…**: `./setup.sh`
2. **å¯åŠ¨å¤–éƒ¨æœåŠ¡**: 
   ```bash
   # NATSæœåŠ¡å™¨
   docker run -d --name nats -p 4222:4222 nats:latest
   
   # LLMæœåŠ¡ï¼ˆé€‰æ‹©å…¶ä¸€ï¼‰
   ollama serve  # æˆ–é…ç½®APIå¯†é’¥
   ```
3. **é…ç½®**: ç¼–è¾‘ `config.yml`ï¼ˆå¦‚éœ€è¦ï¼‰
4. **å¯åŠ¨**: `./run.sh`
5. **ç›‘æ§**: æŸ¥çœ‹æ§åˆ¶å°è¾“å‡ºçš„åˆ†æç»“æœ
6. **åœæ­¢**: æŒ‰ `Ctrl+C`

## ğŸ“ˆ è¾“å‡ºç¤ºä¾‹

ç³»ç»Ÿå¯åŠ¨åï¼Œä¼šå®æ—¶è¾“å‡ºåˆ†æç»“æœï¼š

```json
{
  "type": "analysis.sentiment",
  "timestamp": 1748142870135,
  "source": "analyze_agent",
  "sender": "sentiment_analysis_agent",
  "data": {
    "sentiment": "åˆ©å¤š",
    "reason": "æ¶ˆæ¯æåˆ°BTCçªç ´æ–°é«˜ï¼Œå¸‚åœºæƒ…ç»ªç§¯æ",
    "score": 0.8,
    "analysis_time": "2024-12-23T10:30:00.000Z"
  }
}
```

## ğŸ”§ å¼€å‘æ¨¡å¼

å¦‚æœä½ æƒ³è¿›è¡Œå¼€å‘æˆ–è°ƒè¯•ï¼š

```bash
# æ‰‹åŠ¨å¯åŠ¨å„ä¸ªç»„ä»¶
docker run -d --name nats -p 4222:4222 nats:latest
ollama serve  # æˆ–é…ç½®å…¶ä»–LLM
python main.py

# æˆ–è€…è·³è¿‡æœåŠ¡æ£€æŸ¥
./run.sh --skip-service-check
```

## ğŸ—ï¸ ç³»ç»Ÿé›†æˆ

æœ¬ç¨‹åºè®¾è®¡ä¸ºç³»ç»Ÿçš„ä¸€ä¸ªç»„ä»¶ï¼š

```
TelegramStream â†’ NATS â†’ AnalyzeAgent â†’ åˆ†æç»“æœ
```

- **è¾“å…¥**: æ¥è‡ªTelegramStreamçš„æ¶ˆæ¯ï¼ˆé€šè¿‡NATSï¼‰
- **å¤„ç†**: ä½¿ç”¨LLMè¿›è¡Œæƒ…ç»ªåˆ†æ
- **è¾“å‡º**: ç»“æ„åŒ–çš„åˆ†æç»“æœï¼ˆJSONæ ¼å¼ï¼‰

## âš ï¸ é‡è¦æé†’

**æœ¬ç¨‹åºåªè´Ÿè´£åˆ†æå¤„ç†ï¼Œä¸ä¼šå¯åŠ¨ä»»ä½•å¤–éƒ¨æœåŠ¡ã€‚**

åœ¨è¿è¡Œç¨‹åºå‰ï¼Œè¯·ç¡®ä¿ï¼š
1. âœ… NATSæœåŠ¡å™¨å·²å¯åŠ¨å¹¶å¯è®¿é—®
2. âœ… LLMæœåŠ¡å·²å¯åŠ¨å¹¶å¯è®¿é—®ï¼ˆOllama/OpenAI/Anthropicï¼‰
3. âœ… é…ç½®æ–‡ä»¶æ­£ç¡®è®¾ç½®

## ğŸ“ è·å–å¸®åŠ©

- æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£: `README.md`
- è¿è¡Œå¸®åŠ©å‘½ä»¤: `./run.sh --help`
- æ£€æŸ¥é…ç½®: `python simple_test.py`

---

ğŸ‰ **Analyze Agent å·²å‡†å¤‡å°±ç»ªï¼Œç­‰å¾…å¤–éƒ¨æœåŠ¡å’Œæ¶ˆæ¯è¾“å…¥ï¼** 